# -*- coding: utf-8 -*-
"""Breast_Cancer_Detection.ipynb

Automatically generated by Colaboratory.

Original file is located at
  https://colab.research.google.com/drive/1FxqGxLz6FwFYcH9sKg9O85NyXtFCpbYi?usp=sharing
"""

#Description: The purpose of this object is to successfully detect breast cancer based off of data using a classification model

#Import libraries
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

#Load the data
#from google.colab import files
#uploaded = files.upload()
df = pd.read_csv('data.csv')
df.head(7)

#Count the number of rows and columns in the data set
df.shape

#Count of the number of empty values in each column, represented as NaN
df.isna().sum()

#Drop the last column with all missing values, Unamed: 32
df = df.dropna(axis=1)

#Get the new shape of the dataset 
df.shape

#Get the count of Malignant (M) or Benign (B) cells
df['diagnosis'].value_counts()

#Visualise the count
sns.countplot(df["diagnosis"], label = "count")

#Look at the data types to see which columns need to be encoded
df.dtypes

#Enode the categorical data values
from sklearn.preprocessing import LabelEncoder
labelencoder_Y  = LabelEncoder()
df.iloc[:, 1] = labelencoder_Y.fit_transform(df.iloc[:, 1].values)

#df.iloc[:, 1].values will be represented as 1s and 0s from Ms and Bs

#Create a pair plot
sns.pairplot(df.iloc[:,1:6], hue="diagnosis")

#Print the first 5 rows of the new data
df.head(5)

#Get the correlation of the columns
df.iloc[:,1:].corr()

#Visualize the correlation 
plt.figure(figsize=(20,20))
sns.heatmap(df.iloc[:,1:].corr(), annot=True, fmt = ".0%" )

#Split the dataset into independent (X) and dependent Y) datasets
X = df.iloc[:, 2:].values #Features
Y = df.iloc[:, 1].values #Labels

#Split the dataset into 75% training and 25% testing
from sklearn.model_selection import train_test_split
X_train_unscaled, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.25, random_state = 0)

X_train_unscaled

#Scale the data (Featuring Scaling)
from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
X_train = sc.fit_transform(X_train_unscaled)
X_test = sc.fit_transform(X_test)

#Create a function for the models
def models(X_train, Y_train):

  #Logisitic Regression
  from sklearn.linear_model import LogisticRegression
  log = LogisticRegression(random_state = 0)
  log.fit(X_train, Y_train)

  #Decision Tree
  from sklearn.tree import DecisionTreeClassifier
  tree = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)
  tree.fit(X_train, Y_train)

  #Random Forest Classifier
  from sklearn.ensemble import RandomForestClassifier
  forest = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)
  forest.fit(X_train, Y_train)

  #Print the models accuracy on the training data
  print('[0]Logistic Regression Training Accuracy: ', log.score(X_train, Y_train))
  print('[1]Decision Tree Classifier Training Accuracy: ', tree.score(X_train, Y_train))
  print('[2]Random Forest Classifier Training Accuracy: ', forest.score(X_train, Y_train))

  return log, tree, forest

#Getting all the models
model = models(X_train, Y_train)

#Test model accuracy test data on confusion matrix
from sklearn.metrics import confusion_matrix

for i in range (len(model)):
  (tn, fp, fn, tp) = confusion_matrix(Y_test, model[i].predict(X_test)).ravel()
  
  print("")
  print("Model", i)

  print('True Negative: ', tn)
  print('True Positive: ', tp)
  print('False Negative: ', fn)
  print('False Positive: ', fp)

  print("Testing Accuracy = ", (((tp + tn)/(tp + tn + fn + fp))*100), "%")
  print("")

#Show another way to get metrics of the models
from sklearn.metrics import classification_report
from sklearn.metrics import accuracy_score

for i in range(len(model)):
  print("")
  print("")
  print("Model", i)
  print(classification_report(Y_test, model[i].predict(X_test)))
  print(accuracy_score(Y_test, model[i].predict(X_test)))
  print("")
  print("")

#Print the prediction of each model
for i in range (len(model)):
  print("")
  print("")
  print("Model:", i)
  pred = model[i].predict(X_test)
  print("Prediciton:")
  print(pred)
  print("")
  print("Actual Result:")
  print(Y_test)
  print("")
  print("")

#Input own data
df_user = df.iloc[:,2:]
feature_columns = df_user.columns

user_data_unscaled = []

for feature in feature_columns:
  print(feature,":")
  data = input()
  user_data_unscaled.append(data)

#Add user_data_unscaled to X_train_unscaled to form Y
#X_train_unscaled.shape
#user_data_unscaled = [np.zeros((30,))]
user_data_unscaled = [user_data_unscaled]
Y = np.append(X_train_unscaled, user_data_unscaled, axis = 0)
Y

#Extract the user's data from Y
Y_scaled = sc.fit_transform(Y)
Z = Y_scaled[-1]
Z

#Convert Z from a numpy array to a 2D list
Z = Z.tolist()
Z = [Z]
Z

#Final output
for i in range (len(model)):
  print("")
  print("Model:", i)
  pred = model[i].predict(Z)
  print("Prediciton:")
  if pred[0] == "1":
    print("Malignant")
  else:
    print("Benign")
  print("")